%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created for Ozan Öktem at 2018-06-04 12:02:09 +0200 


%% Saved with string encoding Unicode (UTF-8) 



@incollection{Ronneberger:2015aa,
	Author = {Ronneberger, O. and Fischer, P. and Brox, T.},
	Booktitle = {{Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III}},
	Date-Added = {2018-06-04 09:58:54 +0000},
	Date-Modified = {2018-06-04 09:58:54 +0000},
	Editor = {Navab, N. and Hornegger, J. and Wells, W. M. and Frangi, A. F.},
	Pages = {234--241},
	Publisher = {Springer Verlag},
	Series = {Lecture Notes in Computer Science},
	Title = {{U-Net}: {C}onvolutional Networks for Biomedical Image Segmentation},
	Volume = {9351},
	Year = {2015}}

@article{Karlsson:2017aa,
	Abstract = {The optimal mass transport problem gives a geometric framework for optimal allocation, and has recently gained significant interest in application areas such as signal processing, image processing, and computer vision. Even though it can be formulated as a linear programming problem, it is in many cases intractable for large problems due to the vast number of variables. A recent development to address this builds on an approximation with an entropic barrier term and solves the resulting optimization problem using Sinkhorn iterations. In this work we extend this methodology to a class of inverse problems. In particular we show that Sinkhorn-type iterations can be used to compute the proximal operator of the transport problem for large problems. A splitting framework is then used to solve inverse problems where the optimal mass transport cost is used for incorporating a priori information. We illustrate the method on problems in computerized tomography. In particular we consider a limited-angle computerized tomography problem, where a priori information is used to compensate for missing measurements.
},
	Author = {Karlsson, J. and Ringh, A.},
	Date-Added = {2018-06-04 09:58:50 +0000},
	Date-Modified = {2018-06-04 09:58:50 +0000},
	Journal = {SIAM Journal on Imaging Sciences},
	Number = {4},
	Pages = {1935--1962},
	Title = {Generalized Sinkhorn iterations for regularizing inverse problems using optimal mass transport},
	Volume = {10},
	Year = {2017}}

@article{Chen:2018aa,
	Author = {Chen, C. and {\"O}ktem, O.},
	Date-Added = {2018-06-04 09:58:43 +0000},
	Date-Modified = {2018-06-04 09:58:43 +0000},
	Journal = {SIAM Journal on Imaging},
	Number = {1},
	Pages = {575--617},
	Title = {Indirect Image Registration with Large Diffeomorphic Deformations},
	Volume = {11},
	Year = {2018}}

@incollection{Burger:2017aa,
	Author = {Burger, M. and Dirks, H. and Frerking, L.},
	Booktitle = {Variational Methods In Imaging and Geometric Control},
	Date-Added = {2018-06-04 09:58:38 +0000},
	Date-Modified = {2018-06-04 09:58:38 +0000},
	Editor = {Bergounioux, M. and Peyr{\'e}, G. and Schn{\"o}rr, C. and Caillau, J.-P. and Haberkorn, T.},
	Journal = {ArXiv},
	Pages = {225--251},
	Publisher = {Walter de Gruyter},
	Series = {Radon Series on Computational and Applied Mathematics},
	Title = {On optical flow models for variational motion estimation},
	Volume = {18},
	Year = {2017}}

@article{Romanov:2016aa,
	Abstract = {We consider tomographic imaging problems where the goal is to obtain both a reconstructed image and a corresponding segmentation. A classical approach is to first reconstruct and then segment the image; more recent approaches use a discrete tomography approach where reconstruction and segmentation are combined to produce a reconstruction that is identical to the segmentation. We consider instead a hybrid approach that simultaneously produces both a reconstructed image and segmentation. We incorporate priors about the desired classes of the segmentation through a Hidden Markov Measure Field Model, and we impose a regularization term for the spatial variation of the classes across neighbouring pixels. We also present an efficient implementation of our algorithm based on state-of-the-art numerical optimization algorithms. Simulation experiments with artificial and real data demonstrate that our combined approach can produce better results than the classical two-step approach.},
	Author = {Romanov, M. and Dahl, B. A. and Dong, Y. and Hansen, P. C.},
	Date-Added = {2018-06-04 09:58:31 +0000},
	Date-Modified = {2018-06-04 09:58:31 +0000},
	Journal = {Inverse Problems in Science and Engineering},
	Number = {8},
	Pages = {1432--1453},
	Title = {Simultaneous tomographic reconstruction and segmentation with class priors},
	Volume = {24},
	Year = {2016}}

@article{Mohammad-Djafari:2009aa,
	Abstract = {In many applications of Computed Tomography (CT), we know that the object under the test is composed of a finite number of materials meaning that the images to be reconstructed are composed of a finite number of homogeneous area. To account for this prior knowledge, we propose a family of Gauss-Markov fields with hidden Potts label fields. Then, using these models in a Bayesian inference framework, we are able to jointly reconstruct the image and segment it in an optimal way. In this paper, we first present these prior models, then propose appropriate Bayesian computational methods (MCMC or Variational Bayes) to compute the Joint Maximum A Posteriori (JMAP) or the posterior mean estimators. We finally provide a few results showing the efficiency of the proposed methods for CT with very limited angle and number of projections.},
	Author = {Mohammad-Djafari, A.},
	Date-Added = {2018-06-04 09:58:26 +0000},
	Date-Modified = {2018-06-04 09:58:26 +0000},
	Journal = {International Journal of Tomography and Statistics},
	Number = {9},
	Pages = {76---92},
	Title = {{G}auss-{M}arkov-{P}otts priors for images in computer tomography resulting to joint optimal reconstruction and segmentation},
	Volume = {11},
	Year = {2009}}

@article{Yoon:2010aa,
	Author = {Yoon, S. and Pineda, A. R. and Fahrig, R.},
	Date-Added = {2018-06-04 09:58:21 +0000},
	Date-Modified = {2018-06-04 09:58:21 +0000},
	Journal = {Medical Physics},
	Number = {5},
	Pages = {2329--2340},
	Title = {Simultaneous segmentation and reconstruction: A level set method approach for limited view computed tomography},
	Volume = {37},
	Year = {2010}}

@article{Hohm:2015aa,
	Abstract = {The Mumford-Shah model is a very powerful variational approach for edge preserving regularization of image reconstruction processes. However, it is algorithmically challenging because one has to deal with a non-smooth and non-convex functional. In this paper, we propose a new efficient algorithmic framework for Mumford-Shah regularization of inverse problems in imaging. It is based on a splitting into specific subproblems that can be solved exactly. We derive fast solvers for the subproblems which are key for an efficient overall algorithm. Our method neither requires a priori knowledge of the gray or color levels nor of the shape of the discontinuity set. We demonstrate the wide applicability of the method for different modalities. In particular, we consider the reconstruction from Radon data, inpainting, and deconvolution. Our method can be easily adapted to many further imaging setups. The relevant condition is that the proximal mapping of the data fidelity can be evaluated a within reasonable time. In other words, it can be used whenever classical Tikhonov regularization is possible.
},
	Author = {Hohm, K. and Storath, M. and Weinmann, A.},
	Date-Added = {2018-06-04 09:58:17 +0000},
	Date-Modified = {2018-06-04 09:58:17 +0000},
	Journal = {Inverse Problems},
	Number = {11},
	Pages = {115011 (30pp)},
	Title = {An algorithmic framework for {M}umford-{S}hah regularization of inverse problems in imaging},
	Volume = {31},
	Year = {2015}}

@article{Ramlau:2007aa,
	Abstract = {A level-set based approach for the determination of a piecewise constant density function from data of its Radon transform is presented. Simultaneously, a segmentation of the reconstructed density is obtained. The segmenting contour and the corresponding density are found as minimizers of a Mumford--Shah like functional over the set of admissible contours and -- for a fixed contour -- over the space of piecewise constant densities which may be discontinuous across the contour. Shape sensitivity analysis is used to find a descent direction for the cost functional which leads to an update formula for the contour in the level-set framework. The descent direction can be chosen with respect to different metrics. The use of an L2-type and an H1-type metric is proposed and the corresponding steepest descent flow equations are derived. A heuristic approach for the insertion of additional components of the density is presented. The method is tested for several data sets including synthetic as well as real-world data. It is shown that the method works especially well for large data noise (∼10% noise). The choice of the H1-metric for the determination of the descent direction is found to have positive effect on the number of level-set steps necessary for finding the optimal contours and densities.},
	Author = {Ramlau, R. and Ring, W.},
	Date-Added = {2018-06-04 09:58:11 +0000},
	Date-Modified = {2018-06-04 09:58:11 +0000},
	Journal = {Journal of Computational Physics},
	Number = {2},
	Pages = {539---557},
	Title = {A {M}umford--{S}hah level-set approach for the inversion and segmentation of {X}-ray tomography data},
	Volume = {221},
	Year = {2007}}

@article{Louis:2011aa,
	Abstract = {A strategy for the derivation of fast, accurate and stable algorithms for combining the reconstruction and the feature extraction step for solving linear ill-posed problems in just one method is presented. The precomputation of special reconstruction kernels with optimized parameters for the combination of the two tasks allows for fast implementations and better results than separate realizations. The concept of order optimality is generalized to the solution of feature reconstruction and to Banach spaces in order to find criteria for the selection of suitable mollifiers. Results from real data in different tomographic modalities and scanning geometries are presented with the direct calculation of derivatives, as in Canny edge detectors, and the Laplacian of the solution used in many segmentation algorithms. The method works also when the searched-for solution is not smooth or when the data are very noisy. This shows the versatility of the approach.

},
	Author = {Louis, A. K.},
	Date-Added = {2018-06-04 09:58:03 +0000},
	Date-Modified = {2018-06-04 09:58:03 +0000},
	Journal = {Inverse Problems},
	Pages = {065010 (21pp)},
	Title = {Feature Reconstruction in Inverse Problems},
	Volume = {27},
	Year = {2011}}

@book{Kutyniok:2012aa,
	Date-Added = {2018-06-04 09:57:56 +0000},
	Date-Modified = {2018-06-04 09:57:56 +0000},
	Editor = {Kutyniok, G. and Labate, D.},
	Publisher = {Springer Verlag},
	Title = {Shearlets: Multiscale Analysis for Multivariate Data},
	Year = {2012}}

@article{Rubinstein:2010aa,
	Author = {Rubinstein, R. and Bruckstein, M. and Elad, M.},
	Date-Added = {2018-06-04 09:57:51 +0000},
	Date-Modified = {2018-06-04 09:57:51 +0000},
	Journal = {Proceedings of the IEEE},
	Number = {6},
	Pages = {1045--1057},
	Title = {Dictionaries for sparse representation modeling},
	Volume = {98},
	Year = {2010}}

@book{Foucart:2013aa,
	Author = {Foucart, S. and Rauhut, H.},
	Date-Added = {2018-06-04 09:57:46 +0000},
	Date-Modified = {2018-06-04 09:57:46 +0000},
	Publisher = {Springer Verlag},
	Title = {Mathematical Introduction to Compressive Sensing},
	Year = {2013}}

@incollection{Burger:2013aa,
	Author = {Burger, M. and Osher, S.},
	Booktitle = {Level Set and PDE Based Reconstruction Methods in Imaging},
	Date-Added = {2018-06-04 09:57:34 +0000},
	Date-Modified = {2018-06-04 09:57:34 +0000},
	Pages = {1--70},
	Publisher = {Springer Verlag},
	Title = {A Guide to the TV Zoo},
	Year = {2013}}

@incollection{Krishnan:2015aa,
	Abstract = {The concept of a shape space is linked both to concepts from geometry and from physics. On one hand, a path-based viscous flow approach leads to Riemannian distances between shapes, where shapes are boundaries of objects that mainly behave like fluids. On the other hand, a state-based elasticity approach induces a (by construction) non-Riemannian dissimilarity measure between shapes, which is given by the stored elastic energy of deformations matching the corresponding objects. The two approaches are both based on variational principles. They are analyzed with regard to different applications, and a detailed comparison is given.},
	Author = {Krishnan, V. P. and Quinto, E. T.},
	Booktitle = {Handbook of Mathematical Methods in Imaging},
	Date-Added = {2018-06-04 09:57:26 +0000},
	Date-Modified = {2018-06-04 09:57:26 +0000},
	Edition = {2nd},
	Editor = {Scherzer, O.},
	Pages = {847--902},
	Publisher = {Springer-Verlag},
	Title = {Microlocal Analysis in Tomography},
	Year = {2015}}

@article{Gillies:2016aa,
	Author = {Gillies, R. J. and Kinahan, P. E. and Hricak, H.},
	Date-Added = {2018-06-04 09:57:21 +0000},
	Date-Modified = {2018-06-04 09:57:21 +0000},
	Journal = {Radiology},
	Number = {2},
	Pages = {563--577},
	Title = {Radiomics: Images Are More than Pictures, They Are Data},
	Volume = {278},
	Year = {2016}}

@conference{Zhu:2017aa,
	Author = {Zhu, J.-Y. and Park, T. and Isola, P. and Efros, A. A.},
	Booktitle = {{2017 IEEE International Conference on Computer Vision (ICCV)}},
	Date-Added = {2018-06-04 09:57:11 +0000},
	Date-Modified = {2018-06-04 09:57:11 +0000},
	Pages = {2242--2251},
	Title = {Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks},
	Year = {2017}}

@article{Adler:2017ab,
	Author = {Adler, J. and Ringh, A. and {\"O}ktem, O. and Karlsson, J.},
	Date-Added = {2018-06-04 09:57:03 +0000},
	Date-Modified = {2018-06-04 09:57:03 +0000},
	Journal = {ArXiv},
	Note = {Poster in NIPS 2017},
	Title = {Learning to solve inverse problems using {Wasserstein} loss},
	Volume = {1710.10898},
	Year = {2017}}

@article{Kang:2017aa,
	Author = {Eunhee Kang and Junhong Min and Jong Chul Ye},
	Date-Added = {2018-06-04 09:56:58 +0000},
	Date-Modified = {2018-06-04 09:56:58 +0000},
	Doi = {10.1002/mp.12344},
	Journal = {Medical physics},
	Pages = {e360-e375},
	Title = {{WaveNet: a deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction}},
	Volume = {44 10},
	Year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1002/mp.12344}}

@article{Sidky:2012aa,
	Author = {Sidky, E. Y. and J{\o}rgensen, J. H. and Pan, X.},
	Date-Added = {2018-06-04 09:56:50 +0000},
	Date-Modified = {2018-06-04 09:56:50 +0000},
	Journal = {Physics in Medicine \& Biology},
	Number = {10},
	Pages = {3065--3091},
	Title = {Convex optimization problem prototyping for image reconstruction in computed tomography with the {Chambolle-Pock} algorithm},
	Volume = {57},
	Year = {2012}}

@book{Natterer:2001aa,
	Author = {Natterer, F.},
	Date-Added = {2018-06-04 09:56:45 +0000},
	Date-Modified = {2018-06-04 09:56:45 +0000},
	Publisher = {Society for Industrial and Applied Mathematics},
	Series = {Classics in Applied Mathematics},
	Title = {The Mathematics of Computerized Tomography},
	Volume = {32},
	Year = {2001}}

@unpublished{Putzky:2017aa,
	Abstract = {Inverse problems are typically solved by first defining a model and then choosing an inference procedure. With this separation of modeling from inference, inverse problems can be framed in a modular way. For example, variational inference can be applied to a broad class of models. The modularity, however, typically goes away after model parameters have been trained under a chosen inference procedure. During training, model and inference often interact in a way that the model parameters will ultimately be adapted to the chosen inference procedure, posing the two components inseparable after training. But if model and inference become inseperable after training, why separate them in the first place?

We propose a novel learning framework which abandons the dichotomy between model and inference. Instead, we introduce Recurrent Inference Machines (RIM), a class of recurrent neural networks (RNN), that directly learn to solve inverse problems.

We demonstrate the effectiveness of RIMs in experiments on various image reconstruction tasks. We show empirically that RIMs exhibit the desirable convergence behavior of classical inference procedures, and that they can outperform state-of-the-art methods when trained on specialized inference tasks.

Our approach bridges the gap between inverse problems and deep learning, providing a framework for fast progression in the field of inverse problems.},
	Author = {Putzky, P. and Welling, M.},
	Date-Added = {2018-06-04 09:56:40 +0000},
	Date-Modified = {2018-06-04 09:56:40 +0000},
	Title = {Recurrent inference machines for solving inverse problems},
	Url = {https://openreview.net/pdf?id=HkSOlP9lg},
	Year = {2017},
	Bdsk-Url-1 = {https://openreview.net/pdf?id=HkSOlP9lg}}

@article{Hammernik:2018aa,
	Author = {Hammernik, K. and Klatzer, T. ans Kobler, E. and Recht, M. P. and Sodickson, D. K. and Pock, T. and Knoll, F.},
	Date-Added = {2018-06-04 09:56:34 +0000},
	Date-Modified = {2018-06-04 09:56:34 +0000},
	Journal = {Magnetic Resonance in Medicine},
	Number = {6},
	Pages = {3055--3071},
	Title = {Learning a Variational Network for Reconstruction of Accelerated {MRI} Data},
	Volume = {79},
	Year = {2018}}

@conference{Yang:2016aa,
	Abstract = {Compressive Sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR image from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and computational speed, in this paper, we propose a novel deep architecture, dubbed ADMM-Net. ADMM-Net is defined over a data flow graph, which is derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a CS-based MRI model. In the training phase, all parameters of the net, e.g., image transforms, shrinkage functions, etc., are discriminatively trained end-to-end using L-BFGS algorithm. In the testing phase, it has computational overhead similar to ADMM but uses optimized parameters learned from the training data for CS-based reconstruction task. Experiments on MRI image reconstruction under different sampling ratios in k-space demonstrate that it significantly improves the baseline ADMM algorithm and achieves high reconstruction accuracies with fast computational speed.
},
	Author = {Yang, Y. and Sun, J. and Li, H. and Xu, Z.},
	Booktitle = {{Advances in Neural Information Processing Systems 29 (NIPS 2016)}},
	Date-Added = {2018-06-04 09:56:30 +0000},
	Date-Modified = {2018-06-04 10:00:45 +0000},
	Editor = {Lee, D. D. and Sugiyama, M. and Luxburg, U. V. and Guyon, I. and Garnett, R.},
	Pages = {10--18},
	Title = {Deep {ADMM-Net} for Compressive Sensing {MRI}},
	Volume = {29},
	Year = {2016},
	Bdsk-Url-1 = {http://papers.nips.cc/paper/6406-deep-admm-net-for-compressive-sensing-mri.pdf}}

@article{Jin:2017aa,
	Author = {Jin, K. H. and McCann, M. T. and Froustey, E. and Unser, M.},
	Date-Added = {2018-06-04 09:56:17 +0000},
	Date-Modified = {2018-06-04 09:56:17 +0000},
	Journal = {IEEE Transactions on Image Processing},
	Number = {9},
	Pages = {4509--4522},
	Title = {Deep Convolutional Neural Network for Inverse Problems in Imaging},
	Volume = {26},
	Year = {2017}}

@article{Kang:2017ab,
	Author = {Kang, E. and Min, J. and Ye, J. C.},
	Date-Added = {2018-06-04 09:56:12 +0000},
	Date-Modified = {2018-06-04 09:56:12 +0000},
	Journal = {Medical Physics},
	Number = {10},
	Pages = {360--375},
	Title = {A deep convolutional neural network using directional wavelets for low-dose {X-ray CT} reconstruction},
	Volume = {44},
	Year = {2017}}

@article{Zhu:2018aa,
	Author = {Zhu, B. and Liu, J. Z. and Cauley, S. F. and Rosen, B. R. and Rosen, M. S.},
	Date-Added = {2018-06-04 09:55:59 +0000},
	Date-Modified = {2018-06-04 09:55:59 +0000},
	Journal = {Nature},
	Pages = {487--492},
	Title = {Image reconstruction by domain-transform manifold learning},
	Volume = {555},
	Year = {2018}}

@article{Paschalis:2004aa,
	Abstract = {A new image reconstruction technique based on the usage of an Artificial Neural Network (ANN) is presented. The most crucial factor in designing such a reconstruction system is the network architecture and the number of the input projections needed to reconstruct the image. Although the training phase requires a large amount of input samples and a considerable CPU time, the trained network is characterized by simplicity and quick response. The performance of this ANN is tested using several image patterns. It is intended to be used together with a phantom rotating table and the γ-camera of IASA for SPECT image reconstruction.

},
	Author = {Paschalis, P. and Giokaris, N. D. and Karabarbounis, A. and Loudos, G. K. and Maintas, D. and Papanicolas, C. N. and Spanoudaki, V. and Tsoumpas, Ch. and Stiliaris, E.},
	Date-Added = {2018-06-04 09:55:53 +0000},
	Date-Modified = {2018-06-04 09:55:53 +0000},
	Journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
	Number = {1--2},
	Pages = {211--215},
	Title = {Tomographic image reconstruction using Artificial Neural Networks},
	Volume = {527},
	Year = {2004}}

@conference{Argyrou:2012aa,
	Abstract = {A new approach for tomographic image reconstruction from projections using Artificial Neural Network (ANN) techniques is presented in this work. The design of the proposed reconstruction system is based on simple but efficient network architecture, which best utilizes all available input information. Due to the computational complexity, which grows quadratically with the image size, the training phase of the system is characterized by relatively large CPU times. The trained network, on the contrary, is able to provide all necessary information in a quick and efficient way giving results comparable to other time consuming iterative reconstruction algorithms. The performance of the network studied with a large number of software phantoms is directly compared to other iterative and analytical techniques. For a given image size and projections number, the role of the hidden layers in the network architecture is examined and the quality dependence of the reconstructed image on the size of the geometrical patterns used in the training phase is also investigated. ANN based tomographic image reconstruction can be easily implemented in modern FPGA devices and can serve as a quick initialization method to other complicated and time consuming procedures.
},
	Author = {Argyrou, M. and Maintas, D. and Tsoumpas, C. and Stiliaris, E.},
	Booktitle = {Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), 2012 IEEE},
	Date-Added = {2018-06-04 09:55:49 +0000},
	Date-Modified = {2018-06-04 09:55:49 +0000},
	Title = {Tomographic Image Reconstruction based on Artificial Neural Network {(ANN)} techniques},
	Year = {2012}}

@article{Giryes:2017aa,
	Author = {Giryes, R. and Eldar, Y. C. and Bronstein, A. M. and Sapiro, G.},
	Date-Added = {2018-06-04 09:55:44 +0000},
	Date-Modified = {2018-06-04 09:55:44 +0000},
	Journal = {ArXiv},
	Title = {Tradeoffs between Convergence Speed and Reconstruction Accuracy in Inverse Problems},
	Volume = {1605.09232v2},
	Year = {2017}}

@article{Oymak:2017aa,
	Author = {Oymak, S. and Soltanolkotabi, M.},
	Date-Added = {2018-06-04 09:55:39 +0000},
	Date-Modified = {2018-06-04 09:55:39 +0000},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {2276--2300},
	Title = {Fast and Reliable Parameter Estimation from Nonlinear Observations},
	Volume = {27},
	Year = {2017}}

@conference{Gregor:2010aa,
	Author = {Gregor, K. and LeCun, Y.},
	Booktitle = {ICML 2010: The 27th International Conference on Machine Learning},
	Date-Added = {2018-06-04 09:55:34 +0000},
	Date-Modified = {2018-06-04 09:55:34 +0000},
	Title = {Learning Fast Approximations of Sparse Coding},
	Year = {2010}}

@article{Adler:2017aa,
	Author = {Adler, J. and {\"O}ktem, O.},
	Date-Added = {2018-06-04 09:54:09 +0000},
	Date-Modified = {2018-06-04 09:54:09 +0000},
	Journal = {Inverse Problems},
	Note = {Special issue: 100 Years of the Radon transform},
	Number = {12},
	Pages = {124007 (24pp)},
	Title = {Solving ill-posed inverse problems using iterative deep neural networks},
	Volume = {33},
	Year = {2017}}

@article{Adler:2018aa,
	Author = {Adler, J. and {\"O}ktem, O.},
	Date-Added = {2018-06-04 09:54:09 +0000},
	Date-Modified = {2018-06-04 09:55:23 +0000},
	Journal = {IEEE Transactions on Medical Imaging},
	Number = {6},
	Pages = {1322--1332},
	Title = {Learned Primal-dual Reconstruction},
	Volume = {37},
	Year = {2018}}

@article{Nickl:2017ab,
	Author = {Nickl, R. and S{\"o}hl, J.},
	Date-Added = {2018-06-04 09:53:52 +0000},
	Date-Modified = {2018-06-04 09:53:52 +0000},
	Journal = {Annals of Statistics,},
	Pages = {1664--1693},
	Title = {Nonparametric {Bayesian} Posterior Contraction Rates for Discretely Observed Scalar Diffusions},
	Volume = {45},
	Year = {2017}}

@article{Monard:2017aa,
	Author = {Monard, F. and Nickl, R. and Paternain, G. P.},
	Date-Added = {2018-06-04 09:53:52 +0000},
	Date-Modified = {2018-06-04 09:53:52 +0000},
	Journal = {arXiv},
	Title = {Efficient Nonparametric {Bayesian} Inference for X-ray Transforms},
	Volume = {1708.06332},
	Year = {2017}}

@article{Nickl:2017ac,
	Author = {Nickl, R.},
	Date-Added = {2018-06-04 09:53:52 +0000},
	Date-Modified = {2018-06-04 09:53:52 +0000},
	Journal = {arXiv},
	Title = {{Bernstein-von Mises} Theorems for Statistical Inverse Problems {I}: {Sch{\"o}dinger} Equation},
	Volume = {1707.01764v2},
	Year = {2017}}

@article{Waaij:2016aa,
	Author = {van Waaij, J. and van Zanten, J. H.},
	Date-Added = {2018-06-04 09:53:38 +0000},
	Date-Modified = {2018-06-04 09:53:38 +0000},
	Journal = {Electronic Journal of Statistics,},
	Pages = {628--645},
	Title = {Gaussian Process Methods for One-dimensional Diffusions: Optimal Rates and Adaptation},
	Volume = {10},
	Year = {2016}}

@article{Kekkonen:2016aa,
	Author = {Kekkonen, H. and Lassas, M. and Siltanen, S.},
	Date-Added = {2018-06-04 09:53:31 +0000},
	Date-Modified = {2018-06-04 09:53:31 +0000},
	Journal = {Inverse Problems},
	Pages = {085005},
	Title = {Posterior Consistency and Convergence Rates for {Bayesian} Inversion with Hypoelliptic Operators},
	Volume = {32},
	Year = {2016}}

@article{Ray:2013aa,
	Author = {Ray, K.},
	Date-Added = {2018-06-04 09:53:26 +0000},
	Date-Modified = {2018-06-04 09:53:26 +0000},
	Journal = {Electronic Journal of Statistics},
	Pages = {2516--2549},
	Title = {Bayesian Inverse Problems with Non-conjugate Priors},
	Volume = {7},
	Year = {2013}}

@article{Agapiou:2013aa,
	Author = {Agapiou, S. and Larsson, S. and Stuart, A. M.},
	Date-Added = {2018-06-04 09:53:19 +0000},
	Date-Modified = {2018-06-04 09:53:19 +0000},
	Journal = {Stochastic Processes and their Applications},
	Pages = {3828--3860},
	Title = {Posterior Contraction Rates for the {Bayesian} Approach to Linear Ill-posed Inverse Problems},
	Volume = {123},
	Year = {2013}}

@article{Knapik:2011aa,
	Author = {Knapik, B. and van der Vaart, A. W. and van Zanten, H.},
	Date-Added = {2018-06-04 09:53:15 +0000},
	Date-Modified = {2018-06-04 09:53:15 +0000},
	Journal = {Annals of Statistics},
	Pages = {2626--2657},
	Title = {Bayesian Inverse Problems with {Gaussian} Priors},
	Volume = {39},
	Year = {2011}}

@incollection{Dashti:2016aa,
	Address = {New York},
	Author = {Dashti, M. and Stuart, A.M.},
	Booktitle = {Handbook of Uncertainty Quantification},
	Date-Added = {2018-06-04 09:53:10 +0000},
	Date-Modified = {2018-06-04 09:53:10 +0000},
	Publisher = {Springer Verlag},
	Title = {The {Bayesian} Approach to Inverse Problems},
	Year = {2016}}

@article{Stuart:2010aa,
	Author = {Stuart, A. M.},
	Date-Added = {2018-06-04 09:53:04 +0000},
	Date-Modified = {2018-06-04 09:53:04 +0000},
	Journal = {Acta Numerica},
	Pages = {451--559},
	Title = {Inverse Problems: A {Bayesian} Perspective},
	Volume = {19},
	Year = {2010}}

@article{Nickl:2017aa,
	Author = {Nickl, R.},
	Date-Added = {2018-06-04 09:52:54 +0000},
	Date-Modified = {2018-06-04 09:52:54 +0000},
	Journal = {Bernoulli News},
	Number = {2},
	Pages = {5--9},
	Title = {On {Bayesian} Inference for Some Statistical Inverse Problems with Partial Differential Equations},
	Volume = {24},
	Year = {2017}}

@article{Evans:2002aa,
	Abstract = {What mathematicians, scientists, engineers and statisticians mean by 'inverse problem' differs. For a statistician, an inverse problem is an inference or estimation problem. The data are finite in number and contain errors, as they do in classical estimation or inference problems, and the unknown typically is infinite dimensional, as it is in nonparametric regression. The additional complication in an inverse problem is that the data are only indirectly related to the unknown. Canonical abstract formulations of statistical estimation problems subsume this complication by allowing probability distributions to be indexed in more-or-less arbitrary ways by parameters, which can be infinite dimensional. Standard statistical concepts, questions and considerations such as bias, variance, mean-squared error, identifiability, consistency, efficiency and various forms of optimality apply to inverse problems. This paper discusses inverse problems as statistical estimation and inference problems, and points to the literature for a variety of techniques and results. It shows how statistical measures of performance apply to techniques used in practical inverse problems, such as regularization, maximum penalized likelihood, Bayes estimation and the Backus--Gilbert method. The paper generalizes results of Backus and Gilbert characterizing parameters in inverse problems that can be estimated with finite bias. It also establishes general conditions under which parameters in inverse problems can be estimated consistently.
},
	Author = {Evans, S. N. and Stark, P. B.},
	Date-Added = {2018-06-04 09:52:46 +0000},
	Date-Modified = {2018-06-04 10:02:08 +0000},
	Journal = {Inverse Problems},
	Number = {4},
	Pages = {R1--R55},
	Title = {Inverse problems as statistics},
	Volume = {18},
	Year = {2002},
	Bdsk-Url-1 = {http://stacks.iop.org/0266-5611/18/i=4/a=201}}

@book{Ghosal:2017aa,
	Address = {New York},
	Author = {Ghosal, S. and van der Vaart, A. W.},
	Date-Added = {2018-06-04 09:52:41 +0000},
	Date-Modified = {2018-06-04 09:52:41 +0000},
	Publisher = {Cambridge University Press.},
	Title = {Fundamentals of Nonparametric {Bayesian} Inference},
	Year = {2017}}

@book{Liese:2008aa,
	Address = {New York},
	Author = {Liese, F. and Miescke, K.-J.},
	Date-Added = {2018-06-04 09:52:36 +0000},
	Date-Modified = {2018-06-04 09:52:36 +0000},
	Publisher = {Springer Verlag},
	Series = {Springer Series in Statistics},
	Title = {Statistical Decision Theory: Estimation, Testing, and Selection},
	Year = {2008}}
